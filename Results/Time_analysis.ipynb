{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.spatial import ConvexHull\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from data_types import Experiment\n",
    "\n",
    "\n",
    "def from_db_to_pandas(query):\n",
    "    last = \"\"\n",
    "    headers = []\n",
    "    datasets = []\n",
    "    series = []\n",
    "    serie = None\n",
    "\n",
    "    for experiment in query:\n",
    "        filename = experiment.file_name.rsplit('/')[-1].split(\".\")[0]\n",
    "        if last != filename:\n",
    "            last = filename\n",
    "            dataset_name = filename\n",
    "            datasets.append(dataset_name)\n",
    "            if serie is not None:\n",
    "                series.append(serie)\n",
    "            serie = []\n",
    "        measure = experiment.method.split('.')[-1].replace(\"None\", \"\").replace(\"-R first-last \", \"\").replace(\" -S\", \"\"). \\\n",
    "            replace(\" -W\", \"\").replace(\"_\", \" \").replace(\"Distance\", \"\").replace(\"Dissimilarity\", \"\").strip()\n",
    "        header = measure\n",
    "        if \"Kappa\" in header:\n",
    "            continue\n",
    "        if header not in headers:\n",
    "            headers.append(header)\n",
    "            \n",
    "        serie.append(experiment.time_taken)\n",
    "\n",
    "    series.append(serie)\n",
    "    # print(headers)\n",
    "    # print(len(headers))\n",
    "\n",
    "    return pd.DataFrame(series, index=datasets, columns=headers)\n",
    "\n",
    "def order_dataset(df):\n",
    "    return df.reindex(sorted(df.columns), axis=1)\n",
    "\n",
    "def get_dataset(database):\n",
    "    engine = create_engine(database, echo=False)\n",
    "    session_class = sessionmaker(bind=engine)\n",
    "    session = session_class()\n",
    "    query = session.query(Experiment).order_by(Experiment.file_name, Experiment.id)\n",
    "    # query = for experiment in session.query(Experiment).filter(or_(Experiment.set_id==i for i in [17])).order_by(Experiment.file_name):\n",
    "    # query = for experiment in session.query(Experiment).filter(Experiment.number_of_clusters == Experiment.number_of_classes).order_by(Experiment.file_name):\n",
    "    return order_dataset(from_db_to_pandas(query))\n",
    "\n",
    "def get_datasets(folder):\n",
    "    headers = [\"Eskin\", \"Euclidean\", \"Gambaryan\", \"Goodall\", \"InverseOccurenceFrequency\", \"LearningBased E N\", \"Lin\",\n",
    "               \"LinModified Kappa\", \"LinModified KappaMax\", \"Manhattan\", \"OccurenceFrequency\"]\n",
    "    df = get_dataset(f'sqlite:///{folder}/results_testing.db')\n",
    "    df2 = get_dataset(f'sqlite:///{folder}/results_training.db')\n",
    "    rand = get_dataset(f'sqlite:///{folder}/results_rand.db')\n",
    "    adjusted_rand = get_dataset(f'sqlite:///{folder}/results_adjusted_rand.db')\n",
    "    common_cols = [x for x in df2.columns if x in df.columns and x in rand.columns]\n",
    "    fmeasure = df.loc[:, common_cols].append(df2.loc[:, common_cols])\n",
    "    return fmeasure, rand, adjusted_rand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmeasure, rand, adjusted_rand = get_datasets(\"inputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = fmeasure.mean()\n",
    "f_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "fig, ax = plt.subplots()\n",
    "colors = [plt.cm.tab10(i / float(len(f_mean) - 1)) for i in range(len(f_mean))]\n",
    "ax.bar(f_mean.index, f_mean, color=colors, log=True)\n",
    "\n",
    "ax.set_ylabel('Average time taken (seconds)', fontsize=14)\n",
    "ax.set_xlabel('Measures', fontsize=14)\n",
    "ax.set_yticks([1, 10, 100, 500])\n",
    "ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "for txt in f_mean.index:\n",
    "    ax.text(txt, f_mean[txt] ,f\"{f_mean[txt]:.4f} s\", ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.savefig(f\"Time.svg\", format=\"svg\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
